{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import numpy.linalg as la\n",
    "from tabulate import tabulate\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X):\n",
    "    # X is an n-by-p matrix.\n",
    "    # Returns U an orthonormal matrix.\n",
    "    # eps is a threshold value to identify if a vector\n",
    "    # is nearly a zero vector.\n",
    "    eps = 1e-12\n",
    "\n",
    "    n, p = X.shape\n",
    "    U = np.zeros((n, 0))\n",
    "    for j in range(p):\n",
    "        # Get the j-th column of matrix X\n",
    "        v = X[:, j]\n",
    "        # Write your own code here: Perform the\n",
    "        # orthogonalization by subtracting the projections on\n",
    "        # all columns of U. And then check whether the vector\n",
    "        # you get is nearly a zero vector.\n",
    "        vbar = v - U @ U.T @ v\n",
    "        norm = la.norm(vbar)\n",
    "        if norm > eps:\n",
    "            vbar = (1 / norm) * vbar\n",
    "        U = np.hstack((U, np.reshape(vbar, (n, 1))))\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hilbert_matrix(n):\n",
    "    X = np.array(\n",
    "        [[1.0 / (i + j - 1) for i in range(1, n + 1)] for j in range(1, n + 1)]\n",
    "    )\n",
    "    return X\n",
    "\n",
    "\n",
    "size_hilbert = 7\n",
    "matrix_hilbert = hilbert_matrix(size_hilbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hilbert_error(gs_hilbert, size_hilbert):\n",
    "    ortho_hilbert = gs_hilbert.T @ gs_hilbert\n",
    "    identity = np.eye(size_hilbert)\n",
    "    return la.norm(ortho_hilbert - identity, ord=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error computation checks orthogonality by computing $G.T \\cdot G$, which should yield the identity matrix is we produced an orthonormal basis (i.e. all vectors are orthogonal to the other vectors unless that vector is itself, in which case the dot product should be $1$ since they are normalalized). We check this by evaluating the L1 norm from the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24615611198508858\n"
     ]
    }
   ],
   "source": [
    "gs_hilbert_original = gram_schmidt(matrix_hilbert)\n",
    "error_original = compute_hilbert_error(gs_hilbert_original, size_hilbert)\n",
    "print(error_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, we get an error of approximately 0.25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_gram_schmidt(X):\n",
    "    # Define a threshold value to identify if a vector\n",
    "    # is nearly a zero vector.\n",
    "    eps = 1e-12\n",
    "\n",
    "    n, p = X.shape\n",
    "    U = np.zeros((n, 0))\n",
    "\n",
    "    for j in range(p):\n",
    "        # Get the j-th column of matrix X\n",
    "        v = X[:, j]\n",
    "        for i in range(j):\n",
    "            # Compute and subtract the projection of\n",
    "            # vector v onto the i-th column of U\n",
    "            v = v - np.dot(U[:, i], v) * U[:, i]\n",
    "        v = np.reshape(v, (-1, 1))\n",
    "        # Check whether the vector we get is nearly\n",
    "        # a zero vector\n",
    "        if np.linalg.norm(v) > eps:\n",
    "            # Normalize vector v and append it to U\n",
    "            U = np.hstack((U, v / np.linalg.norm(v)))\n",
    "\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.949993888719218e-09\n"
     ]
    }
   ],
   "source": [
    "gs_hilbert_modified = modified_gram_schmidt(matrix_hilbert)\n",
    "error_modified = compute_hilbert_error(gs_hilbert_modified, size_hilbert)\n",
    "print(error_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, we get an error near 0, a significant improvement from the previous method. Between the original and modified G-S algorithm, the projection of vector onto a column of $U$ is computed differently. In the original, this is computed in a single step, whereas the modified does this separately for each column in $U$. The first approach leads to a error accumulation in calculating the new vector against existing ones together. These small error accumulations can lead to significant error differences when dealing with a large matrix. On the other hand, the modified method subtracts the projection component for the previous columns of $U$ individually, making it less susceptible to the accumulated errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = sio.loadmat('face_emotion_data.mat')\n",
    "d = np.load(\"face_emotion_data.npz\")\n",
    "X = d[\"X\"]\n",
    "y = d[\"y\"]\n",
    "\n",
    "n, p = np.shape(X)\n",
    "\n",
    "# error rate for regularized least squares\n",
    "error_RLS = np.zeros((8, 7))\n",
    "# error rate for truncated SVD\n",
    "error_SVD = np.zeros((8, 7))\n",
    "\n",
    "# SVD parameters to test\n",
    "k_vals = np.arange(9) + 1\n",
    "param_err_SVD = np.zeros(len(k_vals))\n",
    "\n",
    "# RLS parameters to test\n",
    "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
    "param_err_RLS = np.zeros(len(lambda_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_svd(\n",
    "    features: np.ndarray, labels: np.ndarray, k_vals, subset_count: int = 8\n",
    ") -> float:\n",
    "    sample_count, feature_count = features.shape\n",
    "    subset_size = sample_count // subset_count\n",
    "\n",
    "    # Reshape arrays for easier subset-level manipulation\n",
    "    features = features.reshape(subset_count, subset_size, feature_count)\n",
    "    labels = labels.reshape(subset_count, subset_size)\n",
    "\n",
    "    subset_idcs = np.arange(subset_count)\n",
    "    train_set_size = (subset_count - 2) * subset_size\n",
    "    subset_err_counts = np.zeros((subset_count, subset_count))\n",
    "\n",
    "    for reg_index in range(subset_count):\n",
    "        current_hold_out_index = 0\n",
    "\n",
    "        for hold_out_index in range(subset_count):\n",
    "            if reg_index != hold_out_index:\n",
    "                current_features = np.zeros((0, feature_count))\n",
    "                current_labels = np.zeros((0,))\n",
    "\n",
    "                for subset_index in range(subset_count):\n",
    "                    if subset_index != reg_index and subset_index != hold_out_index:\n",
    "                        current_features = np.concatenate(\n",
    "                            (current_features, features[subset_index])\n",
    "                        )\n",
    "                        current_labels = np.concatenate(\n",
    "                            (current_labels, labels[subset_index])\n",
    "                        )\n",
    "\n",
    "                U, S, Vh = la.svd(current_features, full_matrices=True)\n",
    "\n",
    "                reg_weights = []\n",
    "                reg_error_counts = []\n",
    "\n",
    "                for index in range(len(k_vals)):\n",
    "                    num_params = k_vals[index]\n",
    "                    new_U = U[:, :num_params]\n",
    "                    new_S = np.diag(1 / S[:num_params])\n",
    "                    new_Vh = Vh[:num_params, :]\n",
    "\n",
    "                    pseudo_inv_X = new_Vh.T @ new_S.T @ new_U.T\n",
    "                    current_weights = pseudo_inv_X @ current_labels\n",
    "\n",
    "                    reg_predictions = features[reg_index] @ current_weights\n",
    "                    reg_error_counts.append(\n",
    "                        sum(np.sign(reg_predictions) != np.sign(labels[reg_index]))\n",
    "                    )\n",
    "                    param_err_SVD[index] += reg_error_counts[-1]\n",
    "                    reg_weights.append(current_weights)\n",
    "\n",
    "                best_param_index, best_error = None, float(\"inf\")\n",
    "                for i in range(feature_count):\n",
    "                    if reg_error_counts[i] < best_error:\n",
    "                        best_param_index, best_error = i, reg_error_counts[i]\n",
    "\n",
    "                hold_out_predictions = (\n",
    "                    features[hold_out_index] @ reg_weights[best_param_index]\n",
    "                )\n",
    "                subset_err_counts[reg_index][hold_out_index] = (\n",
    "                    sum(\n",
    "                        np.sign(hold_out_predictions) != np.sign(labels[hold_out_index])\n",
    "                    )\n",
    "                    / subset_size\n",
    "                )\n",
    "\n",
    "                error_SVD[reg_index][current_hold_out_index] = subset_err_counts[\n",
    "                    reg_index\n",
    "                ][hold_out_index]\n",
    "                current_hold_out_index += 1\n",
    "\n",
    "    # Average over the entire dataset to find the classification error\n",
    "    cls_err = np.sum(subset_err_counts) / (subset_count * (subset_count - 1))\n",
    "    return cls_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the dataset with all features included\n",
    "full_feat_svd_err = truncated_svd(X, y, np.arange(9) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11160714285714286\n",
      "Error estimate: 11.161%\n"
     ]
    }
   ],
   "source": [
    "param_err_SVD = param_err_SVD / (8 * 7)\n",
    "\n",
    "print(full_feat_svd_err)\n",
    "print(f\"Error estimate: {full_feat_svd_err*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From class, we showed that the $\\hat w_\\lambda = (X^T X + \\lambda I)^{-1} X^T y$.\n",
    "\n",
    "Note the following: $X = U \\Sigma V^T$, $X^T = V \\Sigma^T U^T$, $U^T U = U U^T = I$, $V^T V = V V^T = I$\n",
    "\n",
    "Given these facts, $\\hat w_\\lambda = (V \\Sigma^T U^T U \\Sigma V^T + \\lambda V V^T)^{-1} V \\Sigma^T U^T y$. Then, $\\hat w_\\lambda = (V (\\Sigma^T \\Sigma + \\lambda) V^T)^{-1} V \\Sigma^T U^T y$. We know that $\\Sigma$ is $nxd$ and $\\Sigma^T$ is $dxn$, and since $\\Sigma$ is a diagonal matrix, we know that $\\Sigma^T \\Sigma$ is $dxd$ and a diagonal matrix where the diagonal entries are ${s_i}^2$. Then, we add $\\lambda$ to each diagonal entry of $\\Sigma^T \\Sigma$ since $\\lambda$ was multiplied with $I$. Let $A$ denote the diagonal matrix where the diagonal entries are ${s_i}^2 + \\lambda$. Furthermore, let $B$ be the diagonal matrix where the diagonal entries $\\frac{1}{{s_i}^2 + \\lambda}$. Then, we can simplify and get $\\hat w_\\lambda = V B V^T V \\Sigma^T U^T y = V B \\Sigma^T U^T y$. Again, multiplying $B$ by $\\Sigma^T$ gives us a $dxn$ matrix where the diagonal entries are $\\frac{{s_i}^2}{{s_i}^2 + \\lambda}$, and all other entries are $0$, and denote this new matrix $C$. Thus, we get that $\\hat w_\\lambda = V C U^T y$. Furthermore, $y$ and $\\lambda$ (per parameter iteration) are given, as well as SVD outputs $U$, $\\Sigma$, and $V^T$, which we can use to calculate $U^T$, $C$, and $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_ls(\n",
    "    features: np.ndarray, labels: np.ndarray, subset_count: int = 8\n",
    ") -> float:\n",
    "    sample_count, feature_count = features.shape\n",
    "    subset_size = sample_count // subset_count\n",
    "\n",
    "    # Reshape arrays for easier subset-level manipulation\n",
    "    features = features.reshape(subset_count, subset_size, feature_count)\n",
    "    labels = labels.reshape(subset_count, subset_size)\n",
    "\n",
    "    subset_idcs = np.arange(subset_count)\n",
    "    train_set_size = (subset_count - 2) * subset_size\n",
    "    subset_err_counts = np.zeros((subset_count, subset_count))\n",
    "\n",
    "    for reg_index in range(subset_count):\n",
    "        current_hold_out_index = 0\n",
    "\n",
    "        for hold_out_index in range(subset_count):\n",
    "            if reg_index != hold_out_index:\n",
    "                current_features = np.zeros((0, feature_count))\n",
    "                current_labels = np.zeros((0,))\n",
    "\n",
    "                for subset_index in range(subset_count):\n",
    "                    if subset_index != reg_index and subset_index != hold_out_index:\n",
    "                        current_features = np.concatenate(\n",
    "                            (current_features, features[subset_index])\n",
    "                        )\n",
    "                        current_labels = np.concatenate(\n",
    "                            (current_labels, labels[subset_index])\n",
    "                        )\n",
    "\n",
    "                U, S, Vh = la.svd(current_features, full_matrices=True)\n",
    "\n",
    "                reg_weights = []\n",
    "                reg_error_counts = []\n",
    "\n",
    "                for index in range(len(lambda_vals)):\n",
    "                    lambda_val = lambda_vals[index]\n",
    "                    new_S = np.zeros((feature_count, train_set_size))\n",
    "                    for sigma_index in range(feature_count):\n",
    "                        new_S[sigma_index, sigma_index] = S[sigma_index] / (\n",
    "                            S[sigma_index] ** 2 + lambda_val\n",
    "                        )\n",
    "\n",
    "                    rls_X = Vh.T @ new_S @ U.T\n",
    "                    current_weights = rls_X @ current_labels\n",
    "\n",
    "                    reg_predictions = features[reg_index] @ current_weights\n",
    "                    reg_error_counts.append(\n",
    "                        sum(np.sign(reg_predictions) != np.sign(labels[reg_index]))\n",
    "                    )\n",
    "                    param_err_RLS[index] += reg_error_counts[-1]\n",
    "                    reg_weights.append(current_weights)\n",
    "\n",
    "                best_param_index, best_error = None, float(\"inf\")\n",
    "                for i in range(len(lambda_vals)):\n",
    "                    if reg_error_counts[i] < best_error:\n",
    "                        best_param_index, best_error = i, reg_error_counts[i]\n",
    "\n",
    "                hold_out_predictions = (\n",
    "                    features[hold_out_index] @ reg_weights[best_param_index]\n",
    "                )\n",
    "                subset_err_counts[reg_index][hold_out_index] = (\n",
    "                    sum(\n",
    "                        np.sign(hold_out_predictions) != np.sign(labels[hold_out_index])\n",
    "                    )\n",
    "                    / subset_size\n",
    "                )\n",
    "\n",
    "                error_RLS[reg_index][current_hold_out_index] = subset_err_counts[\n",
    "                    reg_index\n",
    "                ][hold_out_index]\n",
    "                current_hold_out_index += 1\n",
    "\n",
    "    # Average over the entire dataset to find the classification error\n",
    "    cls_err = np.sum(subset_err_counts) / (subset_count * (subset_count - 1))\n",
    "    return cls_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the dataset with all features included\n",
    "full_feat_rls_err = regularized_ls(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04799107142857143\n",
      "Error estimate: 4.799%\n"
     ]
    }
   ],
   "source": [
    "param_err_RLS = param_err_RLS / (8 * 7)\n",
    "\n",
    "print(full_feat_rls_err)\n",
    "print(f\"Error estimate: {full_feat_rls_err*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idcs = [i for i in range(p)]\n",
    "num_trials = 1000\n",
    "\n",
    "# SVD parameters to test\n",
    "k_vals = np.arange(12) + 1\n",
    "param_err_SVD = np.zeros(len(k_vals))\n",
    "\n",
    "# RLS parameters to test\n",
    "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
    "param_err_RLS = np.zeros(len(lambda_vals))\n",
    "\n",
    "all_svd_errors = [0 for i in range(num_trials)]\n",
    "all_rls_errors = [0 for i in range(num_trials)]\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    param_err_SVD = np.zeros(len(k_vals))\n",
    "    param_err_RLS = np.zeros(len(lambda_vals))\n",
    "    new_X = np.hstack((X, X @ np.random.rand(9, 3)))\n",
    "    all_svd_errors[trial] = truncated_svd(new_X, y, np.arange(p + 3) + 1)\n",
    "    all_rls_errors[trial] = regularized_ls(new_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_size = 0.001\n",
    "svd_bin_count = int((max(all_svd_errors) - min(all_svd_errors)) // bin_size)\n",
    "rls_bin_count = int((max(all_rls_errors) - min(all_rls_errors)) // bin_size)\n",
    "\n",
    "plt.hist(\n",
    "    all_svd_errors, bins=svd_bin_count, alpha=0.5, label=\"Truncated SVD\", color=\"red\"\n",
    ")\n",
    "plt.hist(\n",
    "    all_rls_errors, bins=rls_bin_count, alpha=0.5, label=\"Regularized LS\", color=\"blue\"\n",
    ")\n",
    "plt.xlabel(\"Error Rate\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD error mean = 0.0975, standard deviation = 0.0138\n",
      "RLS error mean = 0.0607, standard deviation = 0.0067\n"
     ]
    }
   ],
   "source": [
    "svd_mean, svd_std = np.mean(all_svd_errors), np.std(all_svd_errors)\n",
    "rls_mean, rls_std = np.mean(all_rls_errors), np.std(all_rls_errors)\n",
    "print(f\"SVD error mean = {svd_mean:.4f}, standard deviation = {svd_std:.4f}\")\n",
    "print(f\"RLS error mean = {rls_mean:.4f}, standard deviation = {rls_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, these features will not be useful since they are a linear combination of existing features. Therefore, they will not add any meaningful information. In particular, since the new features are redundant, they are in $span(X)$. As above, we see that RLS outperforms SVD like in the part (a). The error rates are also roughly similar to the error rates seen in part (a), indicating no substantial improvement by adding these new features. Since the new features generated are random linear combinations, the weights we get are slightly different each trial and induces variability in the error rates. Furthermore, we see that RLS seems to have less variability. Overall, less variability and lower error rate indicate RLS appears to be a better solution for this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
